{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMsbVVb3nlByQPZBs0dBqL1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ulubeykhuja/Amaliyot/blob/main/salom_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "96JfDq7leNGT"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequence = 'salom'\n",
        "chars = sorted(list(set(sequence)))\n",
        "print(chars)\n",
        "# char_to_idx = {char: idx for idx, char in enumerate(chars)}\n",
        "# idx_to_char = {idx: char for idx, char in enumerate(chars)}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cas50w39elYC",
        "outputId": "cb88af82-780f-4f13-8276-72b83597800f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['a', 'l', 'm', 'o', 's']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "char2idx = {char: idx for idx, char in enumerate(chars)}\n",
        "idx2char = {idx: char for idx, char in enumerate(chars)}"
      ],
      "metadata": {
        "id": "-ejeSzBSe64F"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_data = [char2idx[char] for char in sequence[:-1]]\n",
        "y_data = [char2idx[char] for char in sequence[1:]]\n",
        "\n",
        "x = torch.tensor(x_data).unsqueeze(1)\n",
        "y = torch.tensor(y_data)\n",
        "\n",
        "x.shape, y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DtqIy98OfCrL",
        "outputId": "c0bf9a16-feea-459c-b615-d24bad04f8cd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([4, 1]), torch.Size([4]))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class HarfRNN(nn.Module):\n",
        "  def __init__(self, vocab_size, hidden_size):\n",
        "    super(HarfRNN, self).__init__()\n",
        "    self.rnn = nn.RNN(vocab_size, hidden_size)\n",
        "    self.fc = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "  def forward(self, x, hidden):\n",
        "    out, hidden = self.rnn(x, hidden)\n",
        "    out = self.fc(out.squeeze(1))\n",
        "    return out, hidden\n",
        "\n"
      ],
      "metadata": {
        "id": "bhsfM4Q0f3mX"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(chars)\n",
        "hidden_size = 8\n",
        "model = HarfRNN(vocab_size, hidden_size)"
      ],
      "metadata": {
        "id": "M021aYRXg4ba"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot(index, vocab_size):\n",
        "  vec = torch.zeros(1, 1, vocab_size)\n",
        "  vec[0][0][index] = 1\n",
        "  return vec"
      ],
      "metadata": {
        "id": "2gYWZ5nyg4dt"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)"
      ],
      "metadata": {
        "id": "jNI6Tg_Og4gj"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(100):\n",
        "   loss = 0\n",
        "   h = torch.zeros(1,1,hidden_size)\n",
        "\n",
        "   for i in range(len(x)):\n",
        "    input_vec = one_hot(x[i], vocab_size)\n",
        "    output, h = model(input_vec, h.detach( ))\n",
        "    loss += criterion(output, y[i].unsqueeze(0))\n",
        "\n",
        "   optimizer.zero_grad()\n",
        "   loss.backward()\n",
        "   optimizer.step()\n",
        "\n",
        "   if epoch % 10 == 0:\n",
        "    pred_seq = ''\n",
        "    h_test = torch.zeros(1,1,hidden_size)\n",
        "\n",
        "    for i in x_data:\n",
        "      input_vec = one_hot(i, vocab_size)\n",
        "      output, h_test = model(input_vec, h_test)\n",
        "      pred_idx = output.argmax().item()\n",
        "      pred_char = idx2char[pred_idx]\n",
        "      pred_seq += pred_char\n",
        "\n",
        "    print(f'Epoch: {epoch}, Loss: {loss.item()}, Pred: {pred_seq}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ySAFrbOg4i4",
        "outputId": "d5a1aca2-2cc2-46d0-bf4d-44eadb490327"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, Loss: 6.584862232208252, Pred: mmmm\n",
            "Epoch: 10, Loss: 4.869781494140625, Pred: alom\n",
            "Epoch: 20, Loss: 3.0723588466644287, Pred: alom\n",
            "Epoch: 30, Loss: 1.3091171979904175, Pred: alom\n",
            "Epoch: 40, Loss: 0.5413163900375366, Pred: alom\n",
            "Epoch: 50, Loss: 0.2641647160053253, Pred: alom\n",
            "Epoch: 60, Loss: 0.15879419445991516, Pred: alom\n",
            "Epoch: 70, Loss: 0.11214255541563034, Pred: alom\n",
            "Epoch: 80, Loss: 0.08738254010677338, Pred: alom\n",
            "Epoch: 90, Loss: 0.07206176221370697, Pred: alom\n"
          ]
        }
      ]
    }
  ]
}